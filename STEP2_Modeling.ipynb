{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best model, firstly we will try to simplify our problem. In this notebook, different modeling techniques can be found. We will use different encoder, scaler , classifier and try different models. For simplfy to find best model, firstly we will merge functional and functional but needs repair target labels, and assign this to target. Then, we will assign non-functional to 0. First, we will try simple model then we will try to improve it. After finding the best model, we will try it for the multi-class label format. \n",
    "\n",
    "After decided to scaler and encoder, we tried DecisionTree Classifier, ExtraTreesClassifier and Random Forest. We found good results for Random Forest so we decided to do grid search to find best parameters. After we set this, we did feature importance to select best features and drop less important features. This can help us for future, when we want to do feature engineering. \n",
    "\n",
    "After looking the feature importance, we tried XGBoost, K-Nearest and LGBM Classifiers. And, lastly we decided our best model for binary target as Random Forest with grid search. It gave us the best scores. \n",
    "\n",
    "All details about results of these models can be found at the end of this notebook. Every details about models can be found in relative headings also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import KBinsDiscretizer, FunctionTransformer,RobustScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import category_encoders as ce\n",
    "from category_encoders import WOEEncoder\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import TargetEncoder, LeaveOneOutEncoder, JamesSteinEncoder, MEstimateEncoder\n",
    "\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import gc; gc.enable()\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv') #getting new clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=100 # to see all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we dropped some columns for now, because we have categorized versions of them\n",
    "df.drop(columns=['Unnamed: 0','funder','installer','construction_year'],inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy() # to protect original df , take the copy of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['lga','ward'],inplace=True ) #drop these columns for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['permit'] = df1['permit'].astype(bool).astype(int) #changing from True/False to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['public_meeting'] = df1['public_meeting'].astype(bool).astype(int) #changing from True/False to 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to use scaler for numeric columns and encoder for categorical columns. So, we divided columns in two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['basin','region','extraction_type_group','management','payment','water_quality','quantity',\n",
    "               'source','waterpoint_type','decade','installer_cat','funder_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = ['gps_height','longitude','latitude','district_code','population','public_meeting','permit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32259\n",
       "2    22824\n",
       "1     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 = functional water points ,\n",
    "\n",
    "1 = functional but needs repair water points,\n",
    "\n",
    "2 = non-functinal water points\n",
    "\n",
    "We collect functional and functional but needs help target together and make them 1, non-functional is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting together labels and converting them \n",
    "target_status_group = {0:1, 1: 1, 2 : 0}\n",
    "df1['status_group'] = df1['status_group'].replace(target_status_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    36576\n",
       "0    22824\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, 1 shows functional,\n",
    "\n",
    "0 shows non-functional after here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='status_group' #assign out target column as target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Pipeline / Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing X and target \n",
    "\n",
    "used_cols = [c for c in df1.columns.tolist() if c not in [target]]\n",
    "X=df1[used_cols]\n",
    "y=df1[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to divide our X and y to test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use train test split firstly to figure out the problem. After learning from the baseline, we will use cross validation technique to find the best result. Because, it is more convenient and easy to understand how is going on. For some models, we will use both of them to check our results are consistant or not. \n",
    "The metric for competition is balanced accuracy. But, to make sure and understand the progress, we want to check roc_auc score also especially for some models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create empty dataframe to write our results on it to keep when parameters changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=[\"Model\", \"Scaler\",'Encoder',\n",
    "                                   'roc_auc score mean', 'roc_auc score std']) # to see all results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - Robust Scaler/ Target Encoder with LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scale numeric values and encode categorical columns, we will make pipeline and also use it in our model and classifier changes. For the first trial we use Robust Scaler as a scaler. Robust scales variables using statistics that are strong to outliers. Robust Scaler use IQR(Interquartile Range). As a encoder, we will try target encoder which works well with higher cardinality features. Our data has higher unique values also. \n",
    "Our first trial for baseline is Logistic Regression which predicts the probability that a certain instance belongs to a class. We chose balanced as class weight, because our classes have imbalanced. And also, solver is an algorithm to use in the optimization problem and for multiclass problems ‘lbfgs’ can handle multinomial loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.7718855218855218\n",
      "TEST: 0.7742424242424243\n",
      "\n",
      "Balanced Accuracy:\n",
      "==================\n",
      "TRAIN: 0.7514242992528544\n",
      "TEST: 0.7529177387309345\n"
     ]
    }
   ],
   "source": [
    "#making pipeline\n",
    "\n",
    "scaler = RobustScaler()\n",
    "encoder = ce.TargetEncoder(cols=cat_col)\n",
    "\n",
    "# putting numeric columns to scaler and categorical to encoder\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "# getting together our scaler and encoder with preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n",
    "\n",
    "# choosing model\n",
    "lr = LogisticRegression(class_weight = 'balanced', solver = 'lbfgs', random_state=42)\n",
    "\n",
    "# giving all values to pipeline\n",
    "pipe = make_pipeline(preprocessor,lr)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions on training set\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "# to print the results in good way\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_pred_test)}\")\n",
    "\n",
    "print(\"\\nBalanced Accuracy:\"); print(\"=\"*len(\"Balanced Accuracy:\"))\n",
    "print(f\"TRAIN: {balanced_accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {balanced_accuracy_score(y_test, y_pred_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first trial, this values can be chosen as baseline. We have already fine acceptable results for baseline. There is overfit but not much. For better understanding, we will plot confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to plot and understand confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above matrix, we can make some interpretations. Such that, 1129 represents we predicted as non-functional but normally they are functional. And, 1553 shows that we predicted as functional, but normally they are non-functional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will take the roc_auc score with doing LogReg with cross validation to compare other model results. We will take the mean of the scores, and standard deviation to understand better. We choose cv as 5, it gives 5 different results for each trial. We get and use mean of them. This application will give us more accurate results. Instead of train-test splits, we prefer cross validation which splitting train-test itself and do it for 5 times. It takes more time then train-test split so in some models, we will prefer train-test split again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8313663919758361 +/- 0.0040017382683380015\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find better results than splitting even. And this result is better enough for baseline. Std is not too high also. These all results show us the importance of data cleaning. We tried to clean our data well. Maybe because of good cleaning we get good results for simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # first trial is written in results \n",
    "     \"Model\": 'LogReg' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'TargetEncoder',\n",
    "               'roc_auc score mean' : 0.8313,\n",
    "                    'roc_auc score std' : 0.0041}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Robust Scaler/ WoE Encoder with LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight of evidence encoder works as the predictive power of an independent variable accorfing to the dependent variable. It means that bad vs good. Basically, it is calculating the % of events and % of non-events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8317616620004907 +/- 0.0040460161388364115\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "encoder = ce.WOEEncoder(cols=cat_col)\n",
    "\n",
    "# putting numeric columns to scaler and categorical to encoder\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "# getting together our scaler and encoder with preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n",
    "# giving all values to pipeline\n",
    "pipe = make_pipeline(preprocessor,lr)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes better than baseline. So, we will change our encoder to this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'LogReg' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WeO',\n",
    "                'roc_auc score mean' : 0.8318,\n",
    "                    'roc_auc score std' : 0.0040}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaler/ LeaveOneOut Encoder with LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeaveOneOut Encoder excludes the row’s target when calculating the mean target for a level to reduce the effect of outliers. It is good for outliers but we have already cleaned most of our outliers. To make sure, we tried this encoder also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8312797087089017 +/- 0.004066043448636809\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "encoder = ce.LeaveOneOutEncoder(cols=cat_col)\n",
    "\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n",
    "pipe = make_pipeline(preprocessor,lr)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It did not better than WoE encoder. So, we will not change it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'LogReg' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'LeaveOneOut',\n",
    "                'roc_auc score mean' : 0.8313,\n",
    "                    'roc_auc score std' : 0.0041}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaler/ OneHot Encoder with LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8538287641042815 +/- 0.0024018659896273917\n",
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.7922348484848485\n",
      "TEST: 0.790993265993266\n",
      "\n",
      "Balanced Accuracy:\n",
      "==================\n",
      "TRAIN: 0.7773474554272171\n",
      "TEST: 0.7753766770532994\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "encoder = ce.OneHotEncoder(cols=cat_col)\n",
    "\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n",
    "pipe = make_pipeline(preprocessor,lr)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on training set\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "# to print the results in good way\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_pred_test)}\")\n",
    "\n",
    "print(\"\\nBalanced Accuracy:\"); print(\"=\"*len(\"Balanced Accuracy:\"))\n",
    "print(f\"TRAIN: {balanced_accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {balanced_accuracy_score(y_test, y_pred_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although one-hot encoder gives the best value, we choose our encoder as weight of evidence encoder. Because one-hot encoder creates a binary feature for each unique value in column. So, it is not very useful for high cardinality categorical values like our data. Because, it takes too much time to run the model each time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'LogReg' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'OneHot',\n",
    "                'roc_auc score mean' : 0.8538,\n",
    "                    'roc_auc score std' : 0.0024}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMax Scaler/ WoE Encoder with LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the distribution is not Gaussian or the standard deviation is very small, the min-max scaler generally works well. So, we will see and compare our scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831729064936378 +/- 0.0040065625540644\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "encoder = ce.WOEEncoder(cols=cat_col)\n",
    "\n",
    "# putting numeric columns to scaler and categorical to encoder\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "# getting together our scaler and encoder with preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n",
    "# giving all values to pipeline\n",
    "pipe = make_pipeline(preprocessor,lr)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result does not change significantly so, we decided our encoder as WoE and scaler as Robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'LogReg' ,\n",
    "      \"Scaler\": 'MinMax' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.8317,\n",
    "                    'roc_auc score std' : 0.0040}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Different Encoder and Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Encoder</th>\n",
       "      <th>roc_auc score mean</th>\n",
       "      <th>roc_auc score std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>TargetEncoder</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WeO</td>\n",
       "      <td>0.8318</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>LeaveOneOut</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>OneHot</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.8317</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Scaler        Encoder  roc_auc score mean  roc_auc score std\n",
       "0  LogReg  Robust  TargetEncoder              0.8313             0.0041\n",
       "1  LogReg  Robust            WeO              0.8318             0.0040\n",
       "2  LogReg  Robust    LeaveOneOut              0.8313             0.0041\n",
       "3  LogReg  Robust         OneHot              0.8538             0.0024\n",
       "4  LogReg  MinMax            WoE              0.8317             0.0040"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For updated baseline, we choose WeO encoder with Robust scaler. Although, one hot encoder gave better results, it is not very suitable for our dataset which contains high unique numbers in columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From logistic regression, we have 0.83 roc-auc score. To improve this, we will try new models. First trial is Decision Tree Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786350564101643 +/- 0.008901914029896015\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=4, min_samples_leaf=5, \n",
    "                            random_state=42, class_weight='balanced')\n",
    "\n",
    "pipe = make_pipeline(preprocessor,dt)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried decision tree with different parameters and found the best one and used it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'DecisionTreeClassifier' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.7864,\n",
    "                    'roc_auc score std' : 0.0089}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EkstraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8344599352882744 +/- 0.004585041521670182\n"
     ]
    }
   ],
   "source": [
    "rf_extra = ExtraTreesClassifier(max_depth=5, criterion= 'entropy', min_samples_leaf=3, min_samples_split=18, \n",
    "                          random_state=42, n_estimators = 100, class_weight='balanced', n_jobs = -1)\n",
    "\n",
    "pipe = make_pipeline(preprocessor,rf_extra)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees works like a Random Forest. It builds multiple trees and splits nodes using random subsets of features. There are two main differences it does not samples without replacement, and nodes are split on random splits, not best splits. We also used different parameters and tuned them as best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'ExtraTreesClassifier' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.8345,\n",
    "                    'roc_auc score std' : 0.0045}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results are better than decision tree. It gives an idea about that we need to check Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest models can reduce overfitting risk by randomness as building n_estimators, bootstrapping sample and \n",
    "splitting nodes on the best split among a random subset of the features selected at every node and converting non-homogeneous node into best possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919346222336363 +/- 0.0022277007468852186\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1,class_weight='balanced')\n",
    "\n",
    "pipe = make_pipeline(preprocessor,rf)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'RandomForestClassifier' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.9193,\n",
    "                    'roc_auc score std' : 0.0022}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found good results with RandomForest classifier. We played around parameters and find these as a first trial. Now, with grid search we can find better results with tuning our parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Best Parameters with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search shows us the best parameters for model. To understand this, we will do grid search. To run grid search with encoder and scaler as preprocessing takes too much time. So, we copied our dataframe and encoded categorical columns. Then, we used this encoded dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.copy() #taking copy of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical columns and turn them to numeric version\n",
    "encoder = WOEEncoder()\n",
    "\n",
    "for c in cat_col:\n",
    "    df2[str(c) + '_encoded'] = encoder.fit_transform(df2[c].values, df2[target])\n",
    "    df2.drop(columns=c, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing our X and y and train-test splits\n",
    "\n",
    "used_cols1 = [c for c in df2.columns.tolist() if c not in [target]]\n",
    "X1=df2[used_cols1]\n",
    "y1=df2[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [20, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting grid search parameters and fit and run them\n",
    "grid_p = {\"n_estimators\": [20, 50, 100],\n",
    "          \"criterion\": [\"gini\", \"entropy\"],\n",
    "          \"max_features\": ['sqrt', 'log2'],\n",
    "          \"min_samples_split\": [2, 5, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(rf, grid_p, n_jobs=-1, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9218773133232117"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see the best score of grid search\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see the parameters for best score\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find better parameters if we will give more parameters and values to grid search but it can takes hours or maybe our computer can not convert it. We have already run the code for 6 different parameters but during one hour it did not give results. So, we decided to set four parameters for run and we will use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to set estimator \n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9243196643217907 +/- 0.0023412211439206173\n"
     ]
    }
   ],
   "source": [
    "# to see the roc auc score with best parameters\n",
    "scores = cross_val_score(best_rf, X1, y1, cv=5, scoring='roc_auc') \n",
    "print(scores.mean(), \"+/-\", scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'RFC with GridSearch' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.9243,\n",
    "                    'roc_auc score std' : 0.0023}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Encoder</th>\n",
       "      <th>roc_auc score mean</th>\n",
       "      <th>roc_auc score std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>TargetEncoder</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WeO</td>\n",
       "      <td>0.8318</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>LeaveOneOut</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>OneHot</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.8317</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.8345</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>RFC with GridSearch</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Scaler        Encoder  roc_auc score mean  \\\n",
       "0                  LogReg  Robust  TargetEncoder              0.8313   \n",
       "1                  LogReg  Robust            WeO              0.8318   \n",
       "2                  LogReg  Robust    LeaveOneOut              0.8313   \n",
       "3                  LogReg  Robust         OneHot              0.8538   \n",
       "4                  LogReg  MinMax            WoE              0.8317   \n",
       "5  DecisionTreeClassifier  Robust            WoE              0.7864   \n",
       "6    ExtraTreesClassifier  Robust            WoE              0.8345   \n",
       "7  RandomForestClassifier  Robust            WoE              0.9193   \n",
       "8     RFC with GridSearch  Robust            WoE              0.9243   \n",
       "\n",
       "   roc_auc score std  \n",
       "0             0.0041  \n",
       "1             0.0040  \n",
       "2             0.0041  \n",
       "3             0.0024  \n",
       "4             0.0040  \n",
       "5             0.0089  \n",
       "6             0.0045  \n",
       "7             0.0022  \n",
       "8             0.0023  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see importance of the features wirh random forest. First, fit train data then apply feature_importances_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=50, n_jobs=-1, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code cell was taken from our instructor Bryan Arnold's notebook which is about classifiers. We changed the code according to our data and see the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 13 (0.147108)\n",
      "2. feature 1 (0.143442)\n",
      "3. feature 2 (0.141844)\n",
      "4. feature 0 (0.072635)\n",
      "5. feature 9 (0.068399)\n",
      "6. feature 15 (0.062552)\n",
      "7. feature 11 (0.050384)\n",
      "8. feature 4 (0.050012)\n",
      "9. feature 16 (0.034497)\n",
      "10. feature 14 (0.033488)\n",
      "11. feature 8 (0.032305)\n",
      "12. feature 17 (0.031510)\n",
      "13. feature 18 (0.030117)\n",
      "14. feature 3 (0.026134)\n",
      "15. feature 10 (0.025112)\n",
      "16. feature 7 (0.018418)\n",
      "17. feature 12 (0.015914)\n",
      "18. feature 6 (0.009392)\n",
      "19. feature 5 (0.006736)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Printing the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X1.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plotting the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X1.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X1.shape[1]), indices)\n",
    "plt.xlim([-1, X1.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to below graph features 5-6 and 12 have less importance in our model where 13-1 and 2 have higher importance.\n",
    "Now, we will drop last two features and try our model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determination of discarding columns\n",
    "\n",
    "discard = ['public_meeting', 'permit']\n",
    "\n",
    "# to determine our X,y values again according to new dataframe\n",
    "used_cols2 = [c for c in df2.columns.tolist() if c not in [target] + discard]\n",
    "X2, y2 = df2[used_cols2], df2[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9241922995399895 +/- 0.0019821293437990617\n"
     ]
    }
   ],
   "source": [
    "# setting classifier with best grid search parameters and taking roc-auc score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1,class_weight='balanced',\n",
    "                        criterion ='entropy',max_features = 'sqrt', min_samples_split = 10)\n",
    "\n",
    "scores = cross_val_score(rf, X2, y2, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'RFClassifier w/feature selection' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.9242,\n",
    "                    'roc_auc score std' : 0.0020}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gave nearly same results with whole dataset. It shows us that we can do feature engineering with playing around highly important columns in future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Best Important Features of Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make feature selection and engineering in future, we want to see importance of categorical columns. So, we dropped numeric columns and see our feature importance results again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define numeric columns\n",
    "num_col = ['gps_height','longitude','latitude','district_code','population','public_meeting','permit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping numeric columns\n",
    "X1.drop(columns=num_col,inplace=True ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=None, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting data as train and test and fitting to model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 6 (0.223393)\n",
      "2. feature 2 (0.108580)\n",
      "3. feature 8 (0.089631)\n",
      "4. feature 1 (0.081797)\n",
      "5. feature 4 (0.079386)\n",
      "6. feature 9 (0.073318)\n",
      "7. feature 10 (0.068772)\n",
      "8. feature 11 (0.065870)\n",
      "9. feature 7 (0.064373)\n",
      "10. feature 0 (0.058981)\n",
      "11. feature 3 (0.054432)\n",
      "12. feature 5 (0.031466)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking importance again using Bryan Arnold's code from random forest lecture\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Printing the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X1.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plotting the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X1.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X1.shape[1]), indices)\n",
    "plt.xlim([-1, X1.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In between, categorical columns 6 has more importance then all others. It can give idea to us about feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is an efficient and flexiable classifier which implements models with Gradient Boosting. Although, it is very usefull classifier, it can be overfit easily. So, parameter selection is very imporant for XGBoost. We can do grid search also for XGBoost to tune our parameters but it takes too much time. So, we played around our parameters manually and decided the best one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make sure we will use correct dataframe we will set our X , y again\n",
    "\n",
    "used_cols = [c for c in df1.columns.tolist() if c not in [target]]\n",
    "X=df1[used_cols]\n",
    "y=df1[target]\n",
    "\n",
    "# to divide our X and y to test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.9380260942760943\n",
      "TEST: 0.8617845117845118\n",
      "\n",
      "Balanced Accuracy:\n",
      "==================\n",
      "TRAIN: 0.9237369124184338\n",
      "TEST: 0.8389350038141784\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choosing model\n",
    "\n",
    "xgb = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx',\n",
    "                      num_class = 3, maximize = False, eval_metric = 'merror',early_stopping_rounds=10,\n",
    "                        eta = .1,max_depth = 12, colsample_bytree = .4, learning_rate = 0.1,\n",
    "                        max_delta_step=1)\n",
    "\n",
    "pipe = make_pipeline(preprocessor,xgb)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions on training set\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "# to print the results in good way\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_pred_test)}\")\n",
    "\n",
    "print(\"\\nBalanced Accuracy:\"); print(\"=\"*len(\"Balanced Accuracy:\"))\n",
    "print(f\"TRAIN: {balanced_accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {balanced_accuracy_score(y_test, y_pred_test)}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important parameters are learning rate, early stopping round, max_depth and max_delta step for our tuning. When we changed them, results significantly changed. So, we set this parameters according to results which we find. To compare our results and make sure about roc-auc score, we run same model in cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8407004845846584 +/- 0.003506571678737707\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(preprocessor,xgb)\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'XGBoost' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.8407,\n",
    "                    'roc_auc score std' : 0.0035}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found better results before, it is better than baseline but not better than Random Forest. So, we continue to try other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Neigbours Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general principle of k-Neighbors is to find closest in distance of the new point to predefined number of training points and predict the label according to this. First we tried this model without any parameter tuning. According to result, we will decide to tune or leave this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8852624439664136 +/- 0.0023672331839737193\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "pipe = make_pipeline(preprocessor,knn)\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'K-Neigbours' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.8852,\n",
    "                    'roc_auc score std' : 0.0024}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not better than our Random Forest model. So, we leave it also and do not work on tuning the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBM also constructs a gradient boosting model. It has some advantages that faster training speed and higher efficiency with lower memory usage. It is capable large data sets with significantly quicker than XGBoost. So, we will set this classifier and play with parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.8400673400673401\n",
      "TEST: 0.830050505050505\n",
      "\n",
      "Balanced Accuracy:\n",
      "==================\n",
      "TRAIN: 0.8089504218513586\n",
      "TEST: 0.797869555098716\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAEJCAYAAACdVDLqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAUk0lEQVR4nO3deXhU1f3H8fckJIABhCgUFJHVL2IRMKC4IKjgilDBhepTQNSgFZXNDUERRcUqUBVRVBYXiErVp1qoC4gEwR9QQaDQIy64olQpFRICWeb3x0z8zcGQjPwyuSH5vJ5nntyZeyf3ewjzmXPXEwqHw4iIFEsKugARqVwUCiLiUSiIiEehICIehYKIeGoEXUAJagJdgK1AYcC1iFRFyUATYBWwZ9+ZlTEUugDZQRchUg10A5bt+2JlDIWtAPPXfUvOXnUUDhYnN00PugSJU43kEC0bHgLRz9ov5ldsOXEpBMjZW8jOPQVB1yJxyi/USXAHoRK/dbWjUUQ8CgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEo1AQEY9CQUQ8CgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEo1AQEY9CQUQ8CgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEo1AQEY9CQUQ8CgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEUyPoAqqCosJC5k26ne+/+pykpCSuGPMghMM8P/FmCIU4ouUxXDJyAklJSSyY+Wf+ueJdkpNr0O/GcTRv14Gv3AayHhpLjZRUmrZpR/+b7iQpSXmdaOs+XMXk++5k9vyFbFy/lmGDL6VZi1YAXDbwas7r05/XXnqeF599hsKiQs48+wKuHX4rP2z7nltvuIr8/L00bNSYe6c8Qe3ahwTcmvKT0P95Zna5mW00s81mdn0i1xWk9e8vAmDk9Je54KoRvProRF55dCK9rxnFiMdfIhwOsz77bb5yG/hk7UpGz3iVweP/zMuT7wRg3oNj6H/jOEY8/hK10+ryj7f/GmRzqoWZj0/hrpuHsXdPHgAb169lYOYwZs9fyOz5CzmvT3++3PIZLz77DLNeXkDWG0vIz99Lfn4+T0+bTJ9LLufZV96iZZu2vPz8zIBbU74SFgpmdiQwETgN6Ahkmlm7RK0vSB1OP5sBt9wHwPbvv6Fug8P5ym2gdaeTAGjXtQdu9ft8um41bbucRigUIr3xkRQVFrLzPz+y49/f0bJ9BgAt2mfw6bpVgbWlujjq6JZMfeqFn59vXL+WpYveZFD/cxg36o/k7NrJB8uWcFyHTtwxYiiDLz6XTp27kpKSwq3jH+DCfgMoKiriu2+/5rDDGwXYkvKXyJ5CT2Cxc267cy4HmA9cHLuAmdU3s+axjxkzZjRNYE0Jk1yjBs/dO5r5U+6m4xnnEQ6HCYVCANQ8JI3dOTvJy9lF7Tp1f35PzUPSyMvZyeFHNGPzmv8BYMP7i9ibtzuQNlQnvS7oS42UlJ+ft++Ywaix9zLnL2/S9OgWPD7lfv6z/Uf+8cH7THhoGlNmvMB9427mp//uIBQKUVhYyO/OOpFVK7Lp1KVrgC0pf4kMhSOArTHPtwL7fuCHA5/HPrKysrITWFNC/WHsQ4ybt4h5k24nP9otBdiTm0PtOvWolVaHPbk5v3j9ijEP8vZz05l+8xDqNjiMtEMbBFF+tXbWuRdy3PGdAOh57oX8a8M66jdIp8vJ3UirU5fDDm9Iq2OMLz77BICUlBT++u5q7pr0CGNuygyy9HKXyFBIAsIxz0NA0T7LTAVaxD4GDBjQLYE1JcTKv7/KW889DkBKrVqEkpJo1rY9mz/8AICNHyyhVYcutGyfwaaVSykqKmL7d99QVFREnfrp/HP5Yq4YM4nr/jSTnJ920LbLaUE2p1oaesVFrF+zGoAPli2hXfuOdOrclVUrstmTl0dubg6ffuxo1rwl94wZwcr3lwKQllaHUBXbKZzIow9fA7Ef8MbAt7ELOOd2ADsSWEOF6ND9HF647xamXn8ZhQUF9L9xHI2PbsW8B8dQ8GQ+jY9uRace55GUnEyr47sweWh/wuEiLh15NwANm7Zg+ughpNaqTZtOXTnu5DMCblH1M+7+KUwcO4qUlFQOb/Qbxk96hDp169Hv9wP5w0W9CIfDDB1+C4c2SOeKIdcy4bbhTJ/6AElJSYy9b3LQ5ZerUDgcLnupAxDd0bgMOBHIAZYDmc65lWW8tTnw+ZzVX7FzT0FCapPyd0bzhkGXIHFKSQ5xTOM0iPTOt+w7P2H9HufcN8AdwLvAWmBuHIEgIgFL6MlLzrm5wNxErkNEylfV2kMiIv9vCgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEo1AQEY9CQUQ8CgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEo1AQEY9CQUQ8CgUR8ex32Dgzex1/KHmPc65PQioSkUCVNpbk/AqrQkQqjf2GgnNuTvG0mTUFjgfeBI50zn1ZAbWJSADK3KdgZucDy4FpQCNgo5n1TXRhIhKMeHY03gWcBOxwzm0FTgMmJLQqEQlMPKGQHA0DAJxzayllB6SIHNziCYVcM2tGNAjMrBuQl9CqRCQwpR19KHYr8BbQxMxWAG2A/gmtSkQCU2YoOOdWmFlX4GQgGfjAOfdDwisTkUDE01OAyI7Gs4B84CdgacIqEpFAxXNIcgwwBcgFCoGnzez6RBcmIsGIp6dwOXCSc24ngJk9DCwjct6CiFQx8Rx92A3sKn7inPsPOvogUmWVdkFUv+ikA14zs6eJbD4MBFZXQG0iEoDSNh9u2Of5yJjpRgmoRUQqgdIuiDqjIgsRkcqhzB2NZtYGGAbUAUJEzlVo7Zw7NcG1iUgA4tnROBdIBU4BtgDtgPUJrElEAhRPKNR1zl1H5F4KC4FeRM5uFJEqKJ5Q+DH68xPgt865HegqSZEqK56Tlz4xs6nAHOAZM6sDpCS2LBEJSjw9heuAbOfcGuAp4EwgM6FViUhgQuFwyVsCZpZe2hudc9sTUhE0Bz7fU6BtlINJgy7Dgi5B4tSsSTpuwQSAFkQOHnhK23z4gcjnMrSfn8nlXKuIVAKlnbykgWJEqiF98EXEo1AQEY9CQUQ8cd2OTSNEiVQf8dyO7QI0QpRItRHP5sOdaIQokWpDI0SJiEcjRImIJ54djbehEaJEqo14RoharhGiRKqPeI4+nAC0BL4HvgWaRV8TkSoons2Hv8RMpwJNiNzi/cSEVCQigYpn86FF7HMz6wFckaiCRCRYv/o0Z+fcEiCj/EsRkcognlu8x+4/CAGdgdoJq0hEAvVr9ymEgW1EbtEmIlVQPKEwwjn3WsIrEZFKIZ59ChMTXoWIVBrx9BTWm9kdQDb+kPQfJqwqEQlMPKFwUvRxdcxrYSInNIlIFRNPKHRzzn0d+4KZHZegekQkYPsNhZhxH/4WPWGp+NbuqUSOSLRNeHUiUuFK6ynMIzKYLPzfeJIABcD8hFUkIoEqbdyHcwDMbKZzbkjFlSQiQSrzkKQCQaR60S3eRcSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEo1AQEY9CQUQ8CgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEo1AQEY9CQUQ88YwlecDMrB6wHOjtnNuSyHVVJtu2beOUkzL428K3yc3Npf9FF9K6dRsArhl6HZdcehnPzZnNjCenU1RYSO8+fbn9jnEBV129jB5yNr27tyelRjIzXs5mzcYvefSOARQUFrH5i21cN2Eu4XCYh2+5mK4dWrIrdw8Al4x4kkPr1OaJ8VdQIzmZUAiuv2cem7/YFnCLyk/CQsHMTgKeAo5J1Doqo/z8fIb9cSi1a9cGYO2aD7lx+EiGjxj18zKfffopM56czluLllCzZk3uufsu8vPzSUlJCarsaqVbRhu6Ht+CMwZP5pBaKQwf2JPzu/2W+55ayJvLNjJr4iDO63YcC5ZuoGPbo+hz/TR+3JHz8/sfvuUSnshayutL1tHz5GO554Y+DBj9dIAtKl+J3Hy4Brge+DaB66h0brtlNNdkXkuTJkcAsObDf/D3BX+j5xmnc+01V7Fz504WL3qHjIzOXD1kEL3O7M7Jp5yqQKhAvU45ln9+8i0vTr6Gv/z5WhZmb2Ct+4oG9dIAqJNWi/yCQkKhEK2aNWTa2N+zeNYIBvbtCsBtk19h4bINANRITiJvb0FgbUmEhPUUnHNXA5jZfpcxs/pA/djXRo0a1TQzMzNRZSXUc3Nm07BhQ3qdfQ5/mnQ/AJ27nMjgIVdzQkYGk+6fyMR77qZBgwYsy17Ku9nL2b17N2d2P5VlK1ZRv379MtYg5eGw+mk0a5JOvxufoPmRhzF/6lAmPrmAKbddym1Xn8NPu/JYunozabVTmZ71Ho88v5jkpCT+/tRNfLjxSzZsjnzPtTm6EfePuIhLR84IuEXlK+gdjcOBz2MfWVlZ2cGWdODmzJ7Jonfe5uyzerDuo7VcdeVAzj73PE7IyACgT9+L+GjtGtLTD6Nb9x7UrVuXRo0aceyx7dj88ccBV199bP9vDu+s2ER+QSGbv9hG3t58Zk0cRM8hU+jY715eeGMlD4zsR27eXqbNXcLuvHx25e7hvZWO9sccCcDpndvw0uRMrhr3bJXanwDBh8JUoEXsY8CAAd2CLenAvfPuUt5e/B5vLVrC8R068sysZ7mkX19WrVwJwLuLF9HphAxOPuVUst9bQl5eHjk5OWzatJFWrVsHXH31sXzNZ/Q6pR0ATRoeSlqtmnz29Q/szMkDYOu/d9Cg3iG0OboRi2aNICkpRI0aSZzSqRVrN33F6Z3b8NDNF9N32DQ+3PhlkE1JiIQefSiLc24HsCPIGhLtkcemM+KmYaSmpvKbxo2ZNn0G9erVY9CVV3Hm6acSDoe5fcw40tPTgy612liYvYHTTmjFsudvJhQKMfyBl8jdvYdnH7iSgsIi9uYX8scJc/ly63ZeXLCapc+OJr+gkBfeWMmmz75j9v2DSU1J5qkJAwH4eMv33DAxK+BWlZ9QOBxO6ArMbAvQ41cckmwOfL6nABJbmZSnBl2GBV2CxKlZk3TcggkQ6Z1v2Xd+wnsKzrnmiV6HiJSfoPcpiEglo1AQEY9CQUQ8CgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEo1AQEY9CQUQ8CgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEo1AQEY9CQUQ8CgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfEoFETEo1AQEY9CQUQ8CgUR8SgURMSjUBARj0JBRDwKBRHxKBRExKNQEBGPQkFEPAoFEfHUCLqAEiQXT4SCrEJ+lWZN0oMuQeJ0ZKP6xZPJJc0PhcPhiqsmPqcB2UEXIVINdAOW7ftiZQyFmkAXYCtQGHAt5WbGjBlNs7KysgcMGNAtMzPz66DrkbJV4b9ZMtAEWAXs2XdmZQyFKsnMmgOfAy2cc1uCrUbiUV3/ZtrRKCIehYKIeBQKIuJRKFScHcDd0Z9ycKiWfzPtaBQRj3oKIuJRKIiIpzKe5lwlmdnlwFggBZjqnJsWcElSBjOrBywHeus8BSlXZnYkMJHIKdwdgUwzaxdsVVIaMzuJyCnAxwRdS0VTKFSMnsBi59x251wOMB+4OOCapHTXANcD3wZdSEXT5kPFOILItRzFtgInBlSLxME5dzWAmQVdSoVTT6FiJAGxx35DQFFAtYiUSqFQMb4mclVascZUw26pHBy0+VAx3gHGm1lDIAfoD2QGW5JIydRTqADOuW+AO4B3gbXAXOfcymCrEimZTnMWEY96CiLiUSiIiEehICIehYKIeBQKIuJRKAhmtsvMmptZZzObX8ayXczsiQNYx2NmNr6E18eb2WNlvLeHmW04gHVuMbPOv/Z91Z1OXpKfOedWU/aFWscBTSugHAmIQuEgYmY9gEnAF0BbYDcw2Dm3ycxmA+lAK+ANYFx02e5EBv9YA9zonPvJzLoBjxK5HmMV0R5j9Pc/5pz7rZnViS5zKlAAvAZMByYAh5rZLOfclWZ2IZH7RKQCucBo59yK6L0IngY6ELkArIASRiPap329gTHR39UImOOcGxedXSfai2lN5J6Jmc65j80sdX/t/JX/vBKlzYeDT2fgUefc8cAs4LmYeYc4545zzt0K3Ebkg5jhnOtA5FqLB6IfopeBUc65TkTOsqxdwnomALWAY4ncA+JUIoFzJ5AdDYQ2wH3A+dHflQm8YmZpRG54uptIeF0ClHq5oZmFgFHAIOdcZ6ArcLuZHR5d5ChgsnOuIzA3pt0ltrPUf0EplXoKB5+PnHPFY23OBKaZ2WHR57HfxL2B+kCv6OW/qcA2oD2Q75xbBOCcm2dmT5awnp7ASOdcIZHh+7oDmNngmGV6EbnQa1HMJcZFRL7NewLDnXNh4N9m9mppjXLOhaO9jt7Ru1QdS+Rq0rToIuucc8uj07OB6WZ2aCntlAOkUDj4FMRMFw/MXTzm5q6YecnATc65hQDRzYFawNH8ckDvAn6pgJjLvc3sKCKbB7GSgUXOucv2Wa74CtDY9ZS0jp9FexdrgFeJDDA8E/gdv2xjsTCQz/7bKQdImw8Hn45mdnx0OhNY7pwraVyCN4FhZpZqZknAU8D9wDogZGbnA5hZH6BBCe9/BxhkZklmVpPI3aK6E/lwp0SXWQScbWZto7/r/Ojvrw0sBK6Kvr8B0LeMdrUB6gFjnXOvAz2IDDZcPFx6BzPrGJ0eCixzzuWW0k45QAqFg893wEQzW0/km/QP+1nuHmALkW/fjUS+cUc55/Kj77vHzNYC/Si5u303sBf4KPo7FjjnXgE+AFqa2SvOuY1EginLzD6KrrOPc24XMJ7IN/m/gNeB9WW0ax2RHaT/MrNNwIXRultH528C7oqupw8wqLR2lrEuKYWukjyIxB4dCLoWqbrUUxARj3oKIuJRT0FEPAoFEfEoFETEo1AQEY9CQUQ8CgUR8fwvxVW33atHQR0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#seting model\n",
    "lgbm = LGBMClassifier(booster = 'gbtree', nrounds = 'min.error.idx', maximize = False,eta = .1,max_depth = 10, \n",
    "                      colsample_bytree = .4,learning_rate = 0.1,max_delta_step=1)\n",
    "\n",
    "#sending everthing in pipe\n",
    "pipe = make_pipeline(preprocessor,lgbm)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# predictions on train set\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "# predictions on test set\n",
    "y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_pred_test)}\")\n",
    "\n",
    "print(\"\\nBalanced Accuracy:\"); print(\"=\"*len(\"Balanced Accuracy:\"))\n",
    "print(f\"TRAIN: {balanced_accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {balanced_accuracy_score(y_test, y_pred_test)}\")\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the setting the parameters , our model handled overfit problem easily in this model. But we had better results with Random Forest still. So, we will leave this model here. But, maybe later on for competition submission we can come back and tuned parameters again. Intuitively, we feel that to set LGBM Classifer is easier than XGBoost and it handles the overfit problem more easily. To make sure about our result, we did cross validation one more, and see roc-auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8973295998515114 +/- 0.002589344640728045\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(preprocessor,lgbm)\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'LGBM' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.8973,\n",
    "                    'roc_auc score std' : 0.0025}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Encoder</th>\n",
       "      <th>roc_auc score mean</th>\n",
       "      <th>roc_auc score std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>TargetEncoder</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WeO</td>\n",
       "      <td>0.8318</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>LeaveOneOut</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>OneHot</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.8317</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.8345</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>RFC with GridSearch</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>RFClassifier w/feature selection</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.8407</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>K-Neigbours</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WoE</td>\n",
       "      <td>0.8973</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  Scaler        Encoder  \\\n",
       "0                             LogReg  Robust  TargetEncoder   \n",
       "1                             LogReg  Robust            WeO   \n",
       "2                             LogReg  Robust    LeaveOneOut   \n",
       "3                             LogReg  Robust         OneHot   \n",
       "4                             LogReg  MinMax            WoE   \n",
       "5             DecisionTreeClassifier  Robust            WoE   \n",
       "6               ExtraTreesClassifier  Robust            WoE   \n",
       "7             RandomForestClassifier  Robust            WoE   \n",
       "8                RFC with GridSearch  Robust            WoE   \n",
       "9   RFClassifier w/feature selection  Robust            WoE   \n",
       "10                           XGBoost  Robust            WoE   \n",
       "11                       K-Neigbours  Robust            WoE   \n",
       "12                              LGBM  Robust            WoE   \n",
       "\n",
       "    roc_auc score mean  roc_auc score std  \n",
       "0               0.8313             0.0041  \n",
       "1               0.8318             0.0040  \n",
       "2               0.8313             0.0041  \n",
       "3               0.8538             0.0024  \n",
       "4               0.8317             0.0040  \n",
       "5               0.7864             0.0089  \n",
       "6               0.8345             0.0045  \n",
       "7               0.9193             0.0022  \n",
       "8               0.9243             0.0023  \n",
       "9               0.9242             0.0020  \n",
       "10              0.8407             0.0035  \n",
       "11              0.8852             0.0024  \n",
       "12              0.8973             0.0025  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our results dataframe, the better results for this binary problem is obtained with Random Forest Classifier with grid search. But some results need to play around it. We can do more parameter tuning and can find with LGBM or XGBoost maybe. But this is enough good for us for this step. Because the main problem is to build model with 3-class target. This all notebook gave idea us about what must be our steps for 3-class target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Decided Model for Binary Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.9518728956228957\n",
      "TEST: 0.8602693602693603\n",
      "\n",
      "Balanced Accuracy:\n",
      "==================\n",
      "TRAIN: 0.947773503869161\n",
      "TEST: 0.8470385167371319\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1,class_weight='balanced',\n",
    "                            criterion = 'entropy',max_features = 'sqrt',min_samples_split = 10)\n",
    " \n",
    "pipe = make_pipeline(preprocessor,rf)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# predictions on train set\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "# predictions on test set\n",
    "y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_pred_test)}\")\n",
    "\n",
    "print(\"\\nBalanced Accuracy:\"); print(\"=\"*len(\"Balanced Accuracy:\"))\n",
    "print(f\"TRAIN: {balanced_accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {balanced_accuracy_score(y_test, y_pred_test)}\")\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After decided the model according to roc-auc scores. We looked our balanced accuracy for test set. Because the metric for competition is balanced accuracy. It is overfit, but still giving good test balanced accurancy results. So, we choose this model. LGBM is not over fit and giving near results to this model. These are two good models in this notebook. According to confusion matrix on test data, there is no exact split but it is shown that we will care about 962 points which is already predicted as functional but normally they are non-functional. Also, 698 points are predicted as non-functional but they are functional. With the learnings from binary model, we will continue to 3-class target model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
