{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best model, firstly we will try to simplify our problem. In this notebook, different modeling techniques can be found. We will use different encoder, scaler , classifier and try different models. For simplfy to find best model, firstly we will merge functional and functional but needs repair target labels, and assign this to target. Then, we will assign non-functional to 0. First, we will try simple model then we will try to improve it. After finding the best model, we will try it for the multi-class label format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import KBinsDiscretizer, FunctionTransformer,RobustScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import category_encoders as ce\n",
    "from category_encoders import WOEEncoder\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import TargetEncoder, LeaveOneOutEncoder, JamesSteinEncoder, MEstimateEncoder\n",
    "\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv') #getting new clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=100 # to see all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we dropped some columns for now, because we have categorized versions of them\n",
    "df.drop(columns=['Unnamed: 0','funder','installer','construction_year'],inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy() # to protect original df , take the copy of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['lga','ward'],inplace=True ) #drop these columns for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['permit'] = df1['permit'].astype(bool).astype(int) #changing from True/False to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['public_meeting'] = df1['public_meeting'].astype(bool).astype(int) #changing from True/False to 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to use scaler for numeric columns and encoder for categorical columns. So, we divided columns in two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['basin','region','extraction_type_group','management','payment','water_quality','quantity',\n",
    "               'source','waterpoint_type','decade','installer_cat','funder_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = ['gps_height','longitude','latitude','district_code','population','public_meeting','permit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32259\n",
       "2    22824\n",
       "1     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 = functional water points ,\n",
    "\n",
    "1 = functional but needs repair water points,\n",
    "\n",
    "2 = non-functinal water points\n",
    "\n",
    "We collect functional and functional but needs help target together and make them 1, non-functional is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting together labels and converting them \n",
    "target_status_group = {0:1, 1: 1, 2 : 0}\n",
    "df1['status_group'] = df1['status_group'].replace(target_status_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    36576\n",
       "0    22824\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, 1 shows functional,\n",
    "\n",
    "0 shows non-functional after here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='status_group' #assign out target column as target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Pipeline / Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing X and target \n",
    "\n",
    "used_cols = [c for c in df1.columns.tolist() if c not in [target]]\n",
    "X=df1[used_cols]\n",
    "y=df1[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to divide our X and y to test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use train test split firstly to figure out the problem. After learning from the baseline, we will use cross validation technique to find the best result. Because, it is more convenient and easy to understand how is going on. For some models, we will use both of them to check our results are consistant or not. \n",
    "The metric for competition is balanced accuracy. But, to make sure and understand the progress, we want to check roc_auc score also especially for some models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create empty dataframe to write our results on it to keep when parameters changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=[\"Model\", \"Scaler\",'Encoder',\n",
    "                                   'roc_auc score mean', 'roc_auc score std']) # to see all results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - Robust Scaler/ Target Encoder with LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scale numeric values and encode categorical columns, we will make pipeline and also use it in our model and classifier changes. For the first trial we use Robust Scaler as a scaler. Robust scales variables using statistics that are strong to outliers. Robust Scaler use IQR(Interquartile Range). As a encoder, we will try target encoder which works well with higher cardinality features. Our data has higher unique values also. \n",
    "Our first trial for baseline is Logistic Regression which predicts the probability that a certain instance belongs to a class. We chose balanced as class weight, because our classes have imbalanced. And also, solver is an algorithm to use in the optimization problem and for multiclass problems ‘lbfgs’ can handle multinomial loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.7718855218855218\n",
      "TEST: 0.7742424242424243\n",
      "\n",
      "Balanced Accuracy:\n",
      "==================\n",
      "TRAIN: 0.7514242992528544\n",
      "TEST: 0.7529177387309345\n"
     ]
    }
   ],
   "source": [
    "#making pipeline\n",
    "\n",
    "scaler = RobustScaler()\n",
    "encoder = ce.TargetEncoder(cols=cat_col)\n",
    "\n",
    "# putting numeric columns to scaler and categorical to encoder\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "# getting together our scaler and encoder with preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n",
    "\n",
    "# choosing model\n",
    "lr = LogisticRegression(class_weight = 'balanced', solver = 'lbfgs', random_state=42)\n",
    "\n",
    "# giving all values to pipeline\n",
    "pipe = make_pipeline(preprocessor,lr)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions on training set\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_score = pipe.predict(X_test)\n",
    "\n",
    "# to print the results in good way\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_score)}\")\n",
    "\n",
    "print(\"\\nBalanced Accuracy:\"); print(\"=\"*len(\"Balanced Accuracy:\"))\n",
    "print(f\"TRAIN: {balanced_accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {balanced_accuracy_score(y_test, y_score)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first trial, this values can be chosen as baseline. We have already fine acceptable results for baseline. There is overfit but not much. For better understanding, we will plot confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to plot and understand confusion matrix\n",
    "cm = confusion_matrix(y_test, y_score)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above matrix, we can make some interpretations. Such that, 1129 represents we predicted as non-functional but normally they are functional. And, 1553 shows that we predicted as functional, but normally they are non-functional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will take the roc_auc score with doing LogReg with cross validation to compare other model results. We will take the mean of the scores, and standard deviation to understand better. We choose cv as 5, it gives 5 different results for each trial. We get and use mean of them. This application will give us more accurate results. Instead of train-test splits, we prefer cross validation which splitting train-test itself and do it for 5 times. It takes more time then train-test split so in some models, we will prefer train-test split again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8313663919758361 +/- 0.0040017382683380015\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find better results than splitting even. And this result is better enough for baseline. Std is not too high also. These all results show us the importance of data cleaning. We tried to clean our data well. Maybe because of good cleaning we get good results for simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # first trial is written in results \n",
    "     \"Model\": 'LogReg' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'TargetEncoder',\n",
    "               'roc_auc score mean' : 0.8313,\n",
    "                    'roc_auc score std' : 0.0041}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Robust Scaler/ WoE Encoder with LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight of evidence encoder works as the predictive power of an independent variable accorfing to the dependent variable. It means that bad vs good. Basically, it is calculating the % of events and % of non-events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8317616620004907 +/- 0.0040460161388364115\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "encoder = ce.WOEEncoder(cols=cat_col)\n",
    "\n",
    "# putting numeric columns to scaler and categorical to encoder\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "# getting together our scaler and encoder with preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n",
    "# giving all values to pipeline\n",
    "pipe = make_pipeline(preprocessor,lr)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes better than baseline. So, we will change our encoder to this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'LogReg' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WeO',\n",
    "                'roc_auc score mean' : 0.8318,\n",
    "                    'roc_auc score std' : 0.0040}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaler/ LeaveOneOut Encoder with LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8312797087089017 +/- 0.004066043448636809\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "encoder = ce.LeaveOneOutEncoder(cols=cat_col)\n",
    "\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n",
    "pipe = make_pipeline(preprocessor,lr)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It did not better than WoE encoder. So, we will not change it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'LogReg' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'LeaveOneOut',\n",
    "                'roc_auc score mean' : 0.8313,\n",
    "                    'roc_auc score std' : 0.0041}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaler/ OneHot Encoder with LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8538287641042815 +/- 0.0024018659896273917\n",
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.7922348484848485\n",
      "TEST: 0.790993265993266\n",
      "\n",
      "Balanced Accuracy:\n",
      "==================\n",
      "TRAIN: 0.7773474554272171\n",
      "TEST: 0.7753766770532994\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "encoder = ce.OneHotEncoder(cols=cat_col)\n",
    "\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n",
    "pipe = make_pipeline(preprocessor,lr)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on training set\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_score = pipe.predict(X_test)\n",
    "\n",
    "# to print the results in good way\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_score)}\")\n",
    "\n",
    "print(\"\\nBalanced Accuracy:\"); print(\"=\"*len(\"Balanced Accuracy:\"))\n",
    "print(f\"TRAIN: {balanced_accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {balanced_accuracy_score(y_test, y_score)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although one-hot encoder gives the best value, we choose our encoder as weight of evidence encoder. Because one-hot encoder creates a binary feature for each unique value in column. So, it is not very useful for high cardinality categorical values like our data. Because, it takes too much time to run the model each time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'LogReg' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'OneHot',\n",
    "                'roc_auc score mean' : 0.8538,\n",
    "                    'roc_auc score std' : 0.0024}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMax Scaler/ WoE Encoder with LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831729064936378 +/- 0.0040065625540644\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "encoder = ce.WOEEncoder(cols=cat_col)\n",
    "\n",
    "# putting numeric columns to scaler and categorical to encoder\n",
    "num_transformer = make_pipeline(scaler)\n",
    "cat_transformer = make_pipeline(encoder)\n",
    "\n",
    "# getting together our scaler and encoder with preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "      transformers=[('num', num_transformer, num_col),\n",
    "                    ('cat', cat_transformer, cat_col)])\n",
    "\n",
    "# giving all values to pipeline\n",
    "pipe = make_pipeline(preprocessor,lr)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result does not change significantly so, we decided our encoder as WoE and scaler as Robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'LogReg' ,\n",
    "      \"Scaler\": 'MinMax' , \n",
    "       'Encoder' : 'OneHot',\n",
    "                'roc_auc score mean' : 0.8317,\n",
    "                    'roc_auc score std' : 0.0040}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Different Encoder and Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Encoder</th>\n",
       "      <th>roc_auc score mean</th>\n",
       "      <th>roc_auc score std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>TargetEncoder</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>WeO</td>\n",
       "      <td>0.8318</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>LeaveOneOut</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>Robust</td>\n",
       "      <td>OneHot</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>MinMax</td>\n",
       "      <td>OneHot</td>\n",
       "      <td>0.8317</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Scaler        Encoder  roc_auc score mean  roc_auc score std\n",
       "0  LogReg  Robust  TargetEncoder              0.8313             0.0041\n",
       "1  LogReg  Robust            WeO              0.8318             0.0040\n",
       "2  LogReg  Robust    LeaveOneOut              0.8313             0.0041\n",
       "3  LogReg  Robust         OneHot              0.8538             0.0024\n",
       "4  LogReg  MinMax         OneHot              0.8317             0.0040"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For updated baseline, we choose WeO encoder with Robust scaler. Although, one hot encoder gave better results, it is not very suitable for our dataset which contains high unique numbers in columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786350564101643 +/- 0.008901914029896015\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=4, min_samples_leaf=5, \n",
    "                            random_state=42, class_weight='balanced')\n",
    "\n",
    "pipe = make_pipeline(preprocessor,dt)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'DecisionTreeClassifier' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.7864,\n",
    "                    'roc_auc score std' : 0.0089}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EkstraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8330045498519901 +/- 0.004055072674209609\n"
     ]
    }
   ],
   "source": [
    "rf_ext = ExtraTreesClassifier(max_depth=5, criterion= 'gini', min_samples_leaf=3, min_samples_split=18, \n",
    "                          random_state=42, n_estimators = 57, class_weight='balanced', n_jobs = -1)\n",
    "\n",
    "pipe = make_pipeline(preprocessor,rf_ext)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'ExtraTreesClassifier' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.8330,\n",
    "                    'roc_auc score std' : 0.0041}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919346222336363 +/- 0.0022277007468852186\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1,class_weight='balanced')\n",
    "\n",
    "pipe = make_pipeline(preprocessor,rf)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'RandomForestClassifier' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.9193,\n",
    "                    'roc_auc score std' : 0.0022}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = WOEEncoder()\n",
    "\n",
    "for c in cat_col:\n",
    "    df2[str(c) + '_encoded'] = encoder.fit_transform(df2[c].values, df2[target])\n",
    "    df2.drop(columns=c, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols1 = [c for c in df2.columns.tolist() if c not in [target]]\n",
    "X1=df2[used_cols1]\n",
    "y1=df2[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [20, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_p = {\"n_estimators\": [20, 50, 100],\n",
    "          \"criterion\": [\"gini\", \"entropy\"],\n",
    "          \"max_features\": ['sqrt', 'log2']}\n",
    "\n",
    "grid_search = GridSearchCV(rf, grid_p, n_jobs=-1, cv=5, scoring='roc_auc')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# clf = make_pipeline(preprocessor, \n",
    "#                     GridSearchCV(rf, grid_p,n_jobs=-1, cv=5, scoring='roc_auc',refit=True))\n",
    "\n",
    "# clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9192432433420936"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 100}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [20, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_p = {\"n_estimators\": [20, 50, 100],\n",
    "          \"criterion\": [\"gini\", \"entropy\"],\n",
    "          \"max_features\": ['sqrt', 'log2'],\n",
    "          \"min_samples_split\": [2, 5, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(rf, grid_p, n_jobs=-1, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9218773133232117"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9243196643217907 +/- 0.0023412211439206173\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(best_rf, X1, y1, cv=5, scoring='roc_auc') \n",
    "print(scores.mean(), \"+/-\", scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'RandomForestClassifier' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.9243,\n",
    "                    'roc_auc score std' : 0.0023}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=50, n_jobs=-1, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 13 (0.147108)\n",
      "2. feature 1 (0.143442)\n",
      "3. feature 2 (0.141844)\n",
      "4. feature 0 (0.072635)\n",
      "5. feature 9 (0.068399)\n",
      "6. feature 15 (0.062552)\n",
      "7. feature 11 (0.050384)\n",
      "8. feature 4 (0.050012)\n",
      "9. feature 16 (0.034497)\n",
      "10. feature 14 (0.033488)\n",
      "11. feature 8 (0.032305)\n",
      "12. feature 17 (0.031510)\n",
      "13. feature 18 (0.030117)\n",
      "14. feature 3 (0.026134)\n",
      "15. feature 10 (0.025112)\n",
      "16. feature 7 (0.018418)\n",
      "17. feature 12 (0.015914)\n",
      "18. feature 6 (0.009392)\n",
      "19. feature 5 (0.006736)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X1.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X1.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X1.shape[1]), indices)\n",
    "plt.xlim([-1, X1.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>basin_encoded</th>\n",
       "      <th>region_encoded</th>\n",
       "      <th>extraction_type_group_encoded</th>\n",
       "      <th>management_encoded</th>\n",
       "      <th>payment_encoded</th>\n",
       "      <th>water_quality_encoded</th>\n",
       "      <th>quantity_encoded</th>\n",
       "      <th>source_encoded</th>\n",
       "      <th>waterpoint_type_encoded</th>\n",
       "      <th>decade_encoded</th>\n",
       "      <th>installer_cat_encoded</th>\n",
       "      <th>funder_cat_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1390</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>0.388985</td>\n",
       "      <td>0.948366</td>\n",
       "      <td>0.376213</td>\n",
       "      <td>-0.176906</td>\n",
       "      <td>1.044652</td>\n",
       "      <td>0.115811</td>\n",
       "      <td>0.495996</td>\n",
       "      <td>0.362610</td>\n",
       "      <td>0.379126</td>\n",
       "      <td>-0.038879</td>\n",
       "      <td>0.130852</td>\n",
       "      <td>0.197146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1399</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>-0.090414</td>\n",
       "      <td>-0.549719</td>\n",
       "      <td>0.376213</td>\n",
       "      <td>0.368528</td>\n",
       "      <td>-0.374904</td>\n",
       "      <td>0.115811</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>0.577184</td>\n",
       "      <td>0.379126</td>\n",
       "      <td>0.780469</td>\n",
       "      <td>0.130852</td>\n",
       "      <td>0.197146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>686</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>0.166077</td>\n",
       "      <td>0.300260</td>\n",
       "      <td>0.376213</td>\n",
       "      <td>-0.176906</td>\n",
       "      <td>0.489178</td>\n",
       "      <td>0.115811</td>\n",
       "      <td>0.495996</td>\n",
       "      <td>-0.784097</td>\n",
       "      <td>-0.582060</td>\n",
       "      <td>0.449726</td>\n",
       "      <td>0.617328</td>\n",
       "      <td>0.197146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>263</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>-0.695391</td>\n",
       "      <td>-0.978679</td>\n",
       "      <td>-0.150088</td>\n",
       "      <td>-0.176906</td>\n",
       "      <td>-0.374904</td>\n",
       "      <td>0.115811</td>\n",
       "      <td>-3.906856</td>\n",
       "      <td>-0.335742</td>\n",
       "      <td>-0.582060</td>\n",
       "      <td>-0.576302</td>\n",
       "      <td>0.130852</td>\n",
       "      <td>0.196211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "      <td>-0.090414</td>\n",
       "      <td>-0.014063</td>\n",
       "      <td>0.376213</td>\n",
       "      <td>0.205685</td>\n",
       "      <td>-0.374904</td>\n",
       "      <td>0.115811</td>\n",
       "      <td>0.267114</td>\n",
       "      <td>0.577184</td>\n",
       "      <td>0.379126</td>\n",
       "      <td>-0.082471</td>\n",
       "      <td>0.130852</td>\n",
       "      <td>0.197146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gps_height  longitude   latitude  district_code  population  basin_encoded  \\\n",
       "0        1390  34.938093  -9.856322              5         109       0.388985   \n",
       "1        1399  34.698766  -2.147466              2         280      -0.090414   \n",
       "2         686  37.460664  -3.821329              4         250       0.166077   \n",
       "3         263  38.486161 -11.155298             63          58      -0.695391   \n",
       "4           0  31.130847  -1.825359              1         281      -0.090414   \n",
       "\n",
       "   region_encoded  extraction_type_group_encoded  management_encoded  \\\n",
       "0        0.948366                       0.376213           -0.176906   \n",
       "1       -0.549719                       0.376213            0.368528   \n",
       "2        0.300260                       0.376213           -0.176906   \n",
       "3       -0.978679                      -0.150088           -0.176906   \n",
       "4       -0.014063                       0.376213            0.205685   \n",
       "\n",
       "   payment_encoded  water_quality_encoded  quantity_encoded  source_encoded  \\\n",
       "0         1.044652               0.115811          0.495996        0.362610   \n",
       "1        -0.374904               0.115811          0.014014        0.577184   \n",
       "2         0.489178               0.115811          0.495996       -0.784097   \n",
       "3        -0.374904               0.115811         -3.906856       -0.335742   \n",
       "4        -0.374904               0.115811          0.267114        0.577184   \n",
       "\n",
       "   waterpoint_type_encoded  decade_encoded  installer_cat_encoded  \\\n",
       "0                 0.379126       -0.038879               0.130852   \n",
       "1                 0.379126        0.780469               0.130852   \n",
       "2                -0.582060        0.449726               0.617328   \n",
       "3                -0.582060       -0.576302               0.130852   \n",
       "4                 0.379126       -0.082471               0.130852   \n",
       "\n",
       "   funder_cat_encoded  \n",
       "0            0.197146  \n",
       "1            0.197146  \n",
       "2            0.197146  \n",
       "3            0.196211  \n",
       "4            0.197146  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discard = ['public_meeting', 'permit']\n",
    "used_cols2 = [c for c in df2.columns.tolist() if c not in [target] + discard]\n",
    "X2, y2 = df2[used_cols2], df2[target]\n",
    "\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9241922995399895 +/- 0.0019821293437990617\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1,class_weight='balanced',\n",
    "                        criterion ='entropy',max_features = 'sqrt', min_samples_split = 10)\n",
    "\n",
    "scores = cross_val_score(rf, X2, y2, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.append({       # results written in dataframe\n",
    "     \"Model\": 'RFClassifier w/feature selection' ,\n",
    "      \"Scaler\": 'Robust' , \n",
    "       'Encoder' : 'WoE',\n",
    "                'roc_auc score mean' : 0.9242,\n",
    "                    'roc_auc score std' : 0.0020}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = ['gps_height','longitude','latitude','district_code','population','public_meeting','permit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.drop(columns=num_col,inplace=True ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=None, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 6 (0.223393)\n",
      "2. feature 2 (0.108580)\n",
      "3. feature 8 (0.089631)\n",
      "4. feature 1 (0.081797)\n",
      "5. feature 4 (0.079386)\n",
      "6. feature 9 (0.073318)\n",
      "7. feature 10 (0.068772)\n",
      "8. feature 11 (0.065870)\n",
      "9. feature 7 (0.064373)\n",
      "10. feature 0 (0.058981)\n",
      "11. feature 3 (0.054432)\n",
      "12. feature 5 (0.031466)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X1.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X1.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X1.shape[1]), indices)\n",
    "plt.xlim([-1, X1.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://xgboost.readthedocs.io/en/latest/build.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.9379419191919192\n",
      "TEST: 0.8624579124579125\n",
      "\n",
      "Balanced Accuracy:\n",
      "==================\n",
      "TRAIN: 0.9236170246317847\n",
      "TEST: 0.8395642355050446\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choosing model\n",
    "xgb = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx',\n",
    "                      num_class = 3, maximize = False, eval_metric = 'merror', eta = .1,\n",
    "                      max_depth = 12, colsample_bytree = .4, learning_rate = 0.1)\n",
    "\n",
    "pipe = make_pipeline(preprocessor,xgb)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# make predictions on training set\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "# make predictions on test set\n",
    "y_score = pipe.predict(X_test)\n",
    "\n",
    "# to print the results in good way\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_score)}\")\n",
    "\n",
    "print(\"\\nBalanced Accuracy:\"); print(\"=\"*len(\"Balanced Accuracy:\"))\n",
    "print(f\"TRAIN: {balanced_accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {balanced_accuracy_score(y_test, y_score)}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_score)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8403013310952565 +/- 0.003629546531984922\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx',\n",
    "                      num_class = 3, maximize = False, eval_metric = 'merror', eta = .1,\n",
    "                      max_depth = 12, colsample_bytree = .4, learning_rate = 0.1)\n",
    "\n",
    "pipe = make_pipeline(preprocessor,xgb)\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8852624439664136 +/- 0.0023672331839737193\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "pipe = make_pipeline(preprocessor,knn)\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')\n",
    "print(scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, \n",
    "                                                    stratify=y.values, random_state=42)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "imp_vals, _ = feature_importance_permutation(\n",
    "    predict_method=knn.predict, \n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    metric='accuracy',\n",
    "    num_rounds=1,\n",
    "    seed=1)\n",
    "\n",
    "indices = np.argsort(imp_vals)[::-1]\n",
    "plt.figure()\n",
    "plt.title(\"k-NN feature importance via permutation importance\")\n",
    "plt.bar(range(X.shape[1]), imp_vals[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.ylim([0, 0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#light gbm\n",
    "lgm = LGBMClassifier(booster = 'gbtree', nrounds = 'min.error.idx', maximize = False, eval_metric = 'merror',\n",
    "                     eta = .1,max_depth = 14, colsample_bytree = .4)\n",
    "\n",
    "#fit\n",
    "pipe = make_pipeline(preprocessor,lgm)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on training set\n",
    "y_pred = pipe.predict(X_train)\n",
    "\n",
    "# make predictions on hold-out set\n",
    "y_score = pipe.predict(X_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, y_score)\n",
    "plot_confusion_matrix(cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.8424031986531987\n",
      "TEST: 0.8308922558922559\n",
      "\n",
      "Balanced Accuracy:\n",
      "==================\n",
      "TRAIN: 0.811279742481843\n",
      "TEST: 0.7985537368173805\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_score)}\")\n",
    "\n",
    "print(\"\\nBalanced Accuracy:\"); print(\"=\"*len(\"Balanced Accuracy:\"))\n",
    "print(f\"TRAIN: {balanced_accuracy_score(y_train, y_pred)}\")\n",
    "print(f\"TEST: {balanced_accuracy_score(y_test, y_score)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
